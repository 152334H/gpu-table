[
  {
    "s": "V100",
    "name_full": "???",
    "citation": "https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf#page=15",
    "tdp": 300,
    "sms": 80,
    "cores_cuda": 5120,
    "cores_tensor": 640,
    "register_size": 20971520,
    "cache_l1": 10485760,
    "cache_l2": 6291456,
    "vram": 17179869184,
    "membw": 966367641600,
    "fp32_general": 15700000000000.0,
    "fp16": 120000000000000.0,
    "has_bf16": false,
    "has_tf32": false,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "T4",
    "name_full": "???",
    "citation": "https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/Datasheet_NVIDIA_T4_Virtualization.pdf",
    "tdp": 70,
    "sms": 40,
    "cores_cuda": 2560,
    "cores_tensor": 320,
    "register_size": 10485760,
    "cache_l1": null,
    "cache_l2": null,
    "vram": 17179869184,
    "membw": 343597383680,
    "fp32_general": 8100000000000.0,
    "fp16": 65000000000000.0,
    "has_bf16": false,
    "has_tf32": false,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "2080ti",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf#page=14",
    "tdp": 260,
    "sms": 68,
    "cores_cuda": 4352,
    "cores_tensor": 544,
    "register_size": 17825792,
    "cache_l1": null,
    "cache_l2": 5767168,
    "vram": 11811160064,
    "membw": 343597383680,
    "fp32_general": 14200000000000.0,
    "fp16": 113800000000000.0,
    "has_bf16": false,
    "has_tf32": false,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "Q6000",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf#page=14",
    "tdp": 260,
    "sms": 72,
    "cores_cuda": 4608,
    "cores_tensor": 576,
    "register_size": 18874368,
    "cache_l1": null,
    "cache_l2": 6291456,
    "vram": 25769803776,
    "membw": 721554505728,
    "fp32_general": 16300000000000.0,
    "fp16": 130500000000000.0,
    "has_bf16": false,
    "has_tf32": false,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "Titan",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf#page=44",
    "tdp": 280,
    "sms": 72,
    "cores_cuda": 4608,
    "cores_tensor": null,
    "register_size": 18874368,
    "cache_l1": 7077888,
    "cache_l2": 6291456,
    "vram": 25769803776,
    "membw": 721554505728,
    "fp32_general": 16300000000000.0,
    "fp16": 130500000000000.0,
    "has_bf16": false,
    "has_tf32": false,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "2070",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf#page=44",
    "tdp": 215,
    "sms": 40,
    "cores_cuda": 2560,
    "cores_tensor": 320,
    "register_size": 10485760,
    "cache_l1": 3932160,
    "cache_l2": 4194304,
    "vram": 8589934592,
    "membw": 481036337152,
    "fp32_general": 9100000000000.0,
    "fp16": 72500000000000.0,
    "has_bf16": false,
    "has_tf32": false,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "3070",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf#page=44",
    "tdp": 220,
    "sms": 46,
    "cores_cuda": 5888,
    "cores_tensor": 184,
    "register_size": 12058624,
    "cache_l1": 6029312,
    "cache_l2": 4194304,
    "vram": 8589934592,
    "membw": 481036337152,
    "fp32_general": 20300000000000.0,
    "fp16": 162600000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "3080",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf#page=15",
    "tdp": 320,
    "sms": 68,
    "cores_cuda": 8704,
    "cores_tensor": 272,
    "register_size": 17825792,
    "cache_l1": 8912896,
    "cache_l2": 5242880,
    "vram": 10737418240,
    "membw": 816043786240,
    "fp32_general": 29800000000000.0,
    "fp16": 238000000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "3080ti",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf#page=32",
    "tdp": 350,
    "sms": 80,
    "cores_cuda": 10240,
    "cores_tensor": 320,
    "register_size": 20971520,
    "cache_l1": 10485760,
    "cache_l2": 6291456,
    "vram": 12884901888,
    "membw": 979252543488,
    "fp32_general": 34100000000000.0,
    "fp16": 136400000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "3090",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf#page=44",
    "tdp": 350,
    "sms": 82,
    "cores_cuda": 10496,
    "cores_tensor": 328,
    "register_size": 21495808,
    "cache_l1": 10747904,
    "cache_l2": 6291456,
    "vram": 25769803776,
    "membw": 1005022347264,
    "fp32_general": 35600000000000.0,
    "fp16": 142000000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "3090ti",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf#page=29",
    "tdp": 450,
    "sms": 84,
    "cores_cuda": 10752,
    "cores_tensor": 336,
    "register_size": 22020096,
    "cache_l1": 11010048,
    "cache_l2": 6291456,
    "vram": 25769803776,
    "membw": 1082331758592,
    "fp32_general": 40000000000000.0,
    "fp16": 160000000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "A6000",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf#page=15",
    "tdp": 300,
    "sms": 84,
    "cores_cuda": 10752,
    "cores_tensor": 336,
    "register_size": 22020096,
    "cache_l1": 11010048,
    "cache_l2": 6291456,
    "vram": 51539607552,
    "membw": 824633720832,
    "fp32_general": 38700000000000.0,
    "fp16": 154800000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "A40",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf#page=15",
    "tdp": 300,
    "sms": 84,
    "cores_cuda": 10752,
    "cores_tensor": 336,
    "register_size": 22020096,
    "cache_l1": 11010048,
    "cache_l2": 6291456,
    "vram": 51539607552,
    "membw": 747324309504,
    "fp32_general": 37400000000000.0,
    "fp16": 149700000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "A100",
    "name_full": "???",
    "citation": "https://resources.nvidia.com/en-us-genomics-ep/ampere-architecture-white-paper?xs=169656#page=1",
    "tdp": 400,
    "sms": 108,
    "cores_cuda": 6912,
    "cores_tensor": 432,
    "register_size": 28311552,
    "cache_l1": 11010048,
    "cache_l2": 41943040,
    "vram": 85899345920,
    "membw": 1669668536320,
    "fp32_general": 19500000000000.0,
    "fp16": 312000000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": true,
    "has_fp8": false,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "L4",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf#page=39",
    "tdp": 72,
    "sms": 58,
    "cores_cuda": 7424,
    "cores_tensor": 232,
    "register_size": 15204352,
    "cache_l1": 7602176,
    "cache_l2": 50331648,
    "vram": 25769803776,
    "membw": 322122547200,
    "fp32_general": 30300000000000.0,
    "fp16": 121000000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": false,
    "has_fp8": true,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "L40",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf#page=36",
    "tdp": 300,
    "sms": 142,
    "cores_cuda": 18176,
    "cores_tensor": 568,
    "register_size": 37224448,
    "cache_l1": 18612224,
    "cache_l2": 100663296,
    "vram": 51539607552,
    "membw": 927712935936,
    "fp32_general": 90500000000000.0,
    "fp16": 181000000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": false,
    "has_fp8": true,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "4090",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf#page=13",
    "tdp": 450,
    "sms": 128,
    "cores_cuda": 16384,
    "cores_tensor": 512,
    "register_size": 33554432,
    "cache_l1": 16777216,
    "cache_l2": 75497472,
    "vram": 25769803776,
    "membw": 1082331758592,
    "fp32_general": 82600000000000.0,
    "fp16": 330300000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": false,
    "has_fp8": true,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "4080",
    "name_full": "???",
    "citation": "https://images.nvidia.com/aem-dam/Solutions/Data-Center/l4/nvidia-ada-gpu-architecture-whitepaper-v2.1.pdf#page=13",
    "tdp": 320,
    "sms": 76,
    "cores_cuda": 9728,
    "cores_tensor": 304,
    "register_size": 19922944,
    "cache_l1": 9961472,
    "cache_l2": 67108864,
    "vram": 17179869184,
    "membw": 769657929728,
    "fp32_general": 48700000000000.0,
    "fp16": 194900000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": false,
    "has_fp8": true,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": true
  },
  {
    "s": "H100-PCIe",
    "name_full": "???",
    "citation": "https://resources.nvidia.com/en-us-tensor-core",
    "tdp": 350,
    "sms": 114,
    "cores_cuda": 14592,
    "cores_tensor": 456,
    "register_size": 33792,
    "cache_l1": null,
    "cache_l2": 52428800,
    "vram": 85899345920,
    "membw": 2199023255552,
    "fp32_general": 66900000000000.0,
    "fp16": 756500000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": false,
    "has_fp8": true,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  },
  {
    "s": "H100-SXM",
    "name_full": "???",
    "citation": "https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet",
    "tdp": 700,
    "sms": 132,
    "cores_cuda": 16896,
    "cores_tensor": 528,
    "register_size": 33792,
    "cache_l1": null,
    "cache_l2": 52428800,
    "vram": 85899345920,
    "membw": 3599182594048,
    "fp32_general": 66900000000000.0,
    "fp16": 989400000000000.0,
    "has_bf16": true,
    "has_tf32": true,
    "has_int8": true,
    "has_int4": false,
    "has_fp8": true,
    "has_fp6": false,
    "has_fp4": false,
    "crippled_fp32acc": false
  }
]
